{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#NULL\" data-toc-modified-id=\"NULL-1\"><code>NULL</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#How-NULL-occur\" data-toc-modified-id=\"How-NULL-occur-1.1\">How <code>NULL</code> occur</a></span></li><li><span><a href=\"#Check-NULL\" data-toc-modified-id=\"Check-NULL-1.2\">Check <code>NULL</code></a></span></li></ul></li><li><span><a href=\"#Aggregators\" data-toc-modified-id=\"Aggregators-2\">Aggregators</a></span><ul class=\"toc-item\"><li><span><a href=\"#COUNT\" data-toc-modified-id=\"COUNT-2.1\"><code>COUNT</code></a></span></li><li><span><a href=\"#SUM\" data-toc-modified-id=\"SUM-2.2\"><code>SUM</code></a></span></li><li><span><a href=\"#MIN,-MAX-and-AVG\" data-toc-modified-id=\"MIN,-MAX-and-AVG-2.3\"><code>MIN</code>, <code>MAX</code> and <code>AVG</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Aggegator---Quiz\" data-toc-modified-id=\"Aggegator---Quiz-2.3.1\">Aggegator - Quiz</a></span></li></ul></li></ul></li><li><span><a href=\"#Aggregate-with-GROUP-BY\" data-toc-modified-id=\"Aggregate-with-GROUP-BY-3\">Aggregate with <code>GROUP BY</code></a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#GROUP-BY---Quiz\" data-toc-modified-id=\"GROUP-BY---Quiz-3.0.1\"><code>GROUP BY</code> - Quiz</a></span></li></ul></li><li><span><a href=\"#GROUP-BY-with-multiple-columns---Quiz\" data-toc-modified-id=\"GROUP-BY-with-multiple-columns---Quiz-3.1\"><code>GROUP BY</code> with multiple columns - Quiz</a></span></li></ul></li><li><span><a href=\"#DISTINCT\" data-toc-modified-id=\"DISTINCT-4\"><code>DISTINCT</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#DISTINCT---Quiz\" data-toc-modified-id=\"DISTINCT---Quiz-4.1\"><code>DISTINCT</code> - Quiz</a></span></li></ul></li><li><span><a href=\"#Filter-aggregated-result-with-HAVING\" data-toc-modified-id=\"Filter-aggregated-result-with-HAVING-5\">Filter aggregated result with <code>HAVING</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#HAVING---Quiz\" data-toc-modified-id=\"HAVING---Quiz-5.1\"><code>HAVING</code> - Quiz</a></span></li></ul></li><li><span><a href=\"#DATE-Functions\" data-toc-modified-id=\"DATE-Functions-6\">DATE Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Date-Format-in-SQL\" data-toc-modified-id=\"Date-Format-in-SQL-6.1\">Date Format in SQL</a></span></li><li><span><a href=\"#DATE_TRUC-and-DATE_PART\" data-toc-modified-id=\"DATE_TRUC-and-DATE_PART-6.2\"><code>DATE_TRUC</code> and <code>DATE_PART</code></a></span></li><li><span><a href=\"#More-Date-Functions\" data-toc-modified-id=\"More-Date-Functions-6.3\">More Date Functions</a></span></li><li><span><a href=\"#DATE-Functions---Quiz\" data-toc-modified-id=\"DATE-Functions---Quiz-6.4\">DATE Functions - Quiz</a></span></li></ul></li><li><span><a href=\"#CASE-Functions\" data-toc-modified-id=\"CASE-Functions-7\">CASE Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#CASE\" data-toc-modified-id=\"CASE-7.1\"><code>CASE</code></a></span></li><li><span><a href=\"#CASE-for-Aggregations\" data-toc-modified-id=\"CASE-for-Aggregations-7.2\"><code>CASE</code> for Aggregations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Quiz\" data-toc-modified-id=\"Quiz-7.2.1\">Quiz</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `NULL`\n",
    "\n",
    "## How `NULL` occur\n",
    "\n",
    "> - `NULL`s frequently occur when performing a LEFT or RIGHT JOIN.\n",
    "> - `NULL`s can also occur from simply missing data in our database.\n",
    "\n",
    "## Check `NULL`\n",
    "\n",
    "When identifying NULLs in a WHERE clause, we write `IS NULL` or `IS NOT NULL`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregators\n",
    "\n",
    "## `COUNT`\n",
    "\n",
    "The following queries will return same results if `accounts.id` contain no `NULL`, however, they will differ if `accounts.id` contains `NULL`:\n",
    "\n",
    "```SQL\n",
    "/* count the whole row */\n",
    "SELECT COUNT(*)\n",
    "FROM accounts;\n",
    "\n",
    "/* count a specific column*/\n",
    "SELECT COUNT(accounts.id)\n",
    "FROM accounts;\n",
    "```\n",
    "\n",
    "## `SUM`\n",
    "\n",
    "```SQL\n",
    "/* Find the total amount of poster_qty paper ordered in the orders table.*/\n",
    "SELECT SUM(poster_qty)\n",
    "FROM orders;\n",
    "\n",
    "/* Find the total amount for each individual order that was spent on standard and gloss paper in the orders table. This should give a dollar amount for each order in the table.*/\n",
    "SELECT standard_amt_usd + gloss_amt_usd AS total_standard_gloss\n",
    "FROM orders\n",
    "\n",
    "/*Though the price/standard_qty paper varies from one order to the next. I would like this ratio across all of the sales made in the orders table.*/\n",
    "SELECT SUM(standard_amt_usd)/SUM(standard_qty) Unit_Price\n",
    "FROM orders\n",
    "```\n",
    "\n",
    "\n",
    "## `MIN`, `MAX` and `AVG`\n",
    "\n",
    "`AVG` returns the mean of the data - that is the sum of all of the values in the column divided by the number of values in a column. This aggregate function again ignores the `NULL` values in both the numerator and the denominator.\n",
    "\n",
    "- If you want to count `NULL`s as zero, you will need to use `SUM` and `COUNT`. However, this is probably not a good idea if the `NULL` values truly just represent unknown values for a cell.\n",
    "\n",
    "\n",
    "### Aggegator - Quiz\n",
    "\n",
    "1. When was the earliest order ever placed? You only need to return the date.\n",
    "\n",
    "```SQL\n",
    "SELECT MIN(occurred_at)\n",
    "FROM orders\n",
    "\n",
    "/* Try performing the same query without using an aggregation function.\n",
    "SELECT occurred_at*/\n",
    "FROM orders\n",
    "ORDER BY occurred_at\n",
    "LIMIT 1\n",
    "```\n",
    "\n",
    "2. When did the most recent (latest) web_event occur?\n",
    "```SQL\n",
    "SELECT MAX(occurred_at)\n",
    "FROM web_events\n",
    "```\n",
    "\n",
    "3. what is the MEDIAN total_usd spent on all orders?\n",
    "\n",
    "```SQL\n",
    "SELECT count(total_amt_usd)/2\n",
    "FROM orders\n",
    "/*Result: 3456*/\n",
    "\n",
    "\n",
    "SELECT *\n",
    "FROM ( SELECT total_amt_usd\n",
    "\t   FROM orders\n",
    "\t   ORDER BY total_amt_usd\n",
    "       LIMIT 3457) SUB\n",
    "ORDER BY total_amt_usd DESC\n",
    "LIMIT 2\n",
    "/*result: (2483.16 + 2485.55)/2 = 2482.855 */\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "#  Aggregate with `GROUP BY`\n",
    "\n",
    ">- `GROUP BY` can be used to aggregate data within subsets of the data. For example, grouping for different accounts, different regions, or different sales representatives.\n",
    "\n",
    ">- `GROUP BY` can be used to group by multiple columns as well and the order of column names in your GROUP BY clause doesn’t matter—the results will be the same regardless. \n",
    "\n",
    "\n",
    "\n",
    ">- Any column in the `SELECT` statement that is not within an aggregator must be in the `GROUP BY` clause, e.g. `account_id` in this case:\n",
    "```SQL\n",
    "SELECT account_id, \n",
    "        SUM(standard_qty), SUM(glss_qty), SUM(poster_qty)\n",
    "FROM orders\n",
    "GROUP BY account_id\n",
    "```\n",
    "\n",
    ">- The `GROUP BY` always goes between `WHERE` (if there is one) and `ORDER BY`.\n",
    "\n",
    ">- `ORDER BY` works like `SORT` in spreadsheet software.\n",
    "\n",
    "\n",
    "\n",
    "### `GROUP BY ` - Quiz\n",
    "\n",
    "1. Which account (by name) placed the earliest order? Your solution should have the account name and the date of the order.\n",
    "\n",
    "```SQL\n",
    "\n",
    "/* Method 1*/\n",
    "SELECT a.name, o.occurred_at\n",
    "FROM accounts a\n",
    "JOIN orders o\n",
    "ON o.account_id = a.id\n",
    "ORDER BY occurred_at\n",
    "LIMIT 1\n",
    "\n",
    "```\n",
    "\n",
    "2. Find the total sales in usd for each account. You should include two columns - the total sales for each company's orders in usd and the company name.\n",
    "```SQL\n",
    "SELECT a.name, SUM(total_amt_usd)\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "GROUP BY a.name\n",
    "```\n",
    "\n",
    "3. Via what channel did the most recent (latest) web_event occur, which account was associated with this web_event? Your query should return only three values - the date, channel, and account name.\n",
    "```SQL\n",
    "SELECT w.channel, a.name, w.occurred_at\n",
    "FROM accounts a\n",
    "JOIN web_events w\n",
    "ON w.account_id = a.id\n",
    "ORDER BY w.occurred_at DESC\n",
    "LIMIT 1\n",
    "```\n",
    "\n",
    "4. Find the total number of times each type of channel from the web_events was used. Your final table should have two columns - the channel and the number of times the channel was used.\n",
    "```SQL\n",
    "SELECT channel, COUNT(occurred_at)\n",
    "FROM web_events\n",
    "GROUP BY channel\n",
    "```\n",
    "\n",
    "5. Who was the primary contact associated with the earliest web_event?\n",
    "```SQL\n",
    "SELECT a.primary_poc, w.occurred_at\n",
    "FROM web_events w\n",
    "JOIN accounts a\n",
    "ON w.account_id = a.id\n",
    "ORDER BY w.occurred_at\n",
    "LIMIT 1\n",
    "```\n",
    "\n",
    "6. What was the smallest order placed by each account in terms of total usd. Provide only two columns - the account name and the total usd. Order from smallest dollar amounts to largest.\n",
    "```SQL\n",
    "SELECT a.name, MIN(o.total_amt_usd) min_order\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "GROUP BY name\n",
    "ORDER BY min_order\n",
    "```\n",
    "\n",
    "\n",
    "7. Find the number of sales reps in each region. Your final table should have two columns - the region and the number of sales_reps. Order from fewest reps to most reps.\n",
    "```SQL\n",
    "SELECT r.name, COUNT(DISTINCT s.id) num_reps\n",
    "FROM sales_reps s\n",
    "JOIN region r\n",
    "ON s.region_id = r.id\n",
    "GROUP BY r.name\n",
    "ORDER BY num_reps\n",
    "```\n",
    "\n",
    "## `GROUP BY` with multiple columns - Quiz \n",
    "\n",
    "1. For each account, determine the average amount of each type of paper they purchased across their orders. Your result should have four columns - one for the account name and one for the average quantity purchased for each of the paper types for each account.\n",
    "```SQL\n",
    "SELECT a.name, \n",
    "\t   AVG(standard_qty) avg_standard, \t\n",
    "       AVG(gloss_qty) avg_gloss, \n",
    "       AVG(poster_qty) avg_poster\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "GROUP BY a.name\n",
    "```\n",
    "\n",
    "2. For each account, determine the average amount spent per order on each paper type. Your result should have four columns - one for the account name and one for the average amount spent on each paper type.\n",
    "```SQL\n",
    "SELECT a.name, \n",
    "\t   AVG(standard_amt_usd) avg_standard, \t\n",
    "       AVG(gloss_amt_usd) avg_gloss, \n",
    "       AVG(poster_amt_usd) avg_poster\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "GROUP BY a.name\n",
    "```\n",
    "\n",
    "\n",
    "3. Determine the number of times a particular channel was used in the web_events table for each sales rep. Your final table should have three columns - the name of the sales rep, the channel, and the number of occurrences. Order your table with the highest number of occurrences first.\n",
    "```SQL\n",
    "SELECT s.name, w.channel, COUNT(*) num_events\n",
    "FROM web_events w\n",
    "JOIN accounts a\n",
    "ON w.account_id = a.id\n",
    "JOIN sales_reps s\n",
    "ON a.sales_rep_id = s.id\n",
    "GROUP BY s.name, w.channel\n",
    "ORDER BY num_events DESC\n",
    "```\n",
    "\n",
    "4. Determine the number of times a particular channel was used in the web_events table for each region. Your final table should have three columns - the region name, the channel, and the number of occurrences. Order your table with the highest number of occurrences first.\n",
    "```SQL\n",
    "SELECT r.name, w.channel, COUNT(*) num_events\n",
    "FROM web_events w\n",
    "JOIN accounts a\n",
    "ON w.account_id = a.id\n",
    "JOIN sales_reps s\n",
    "ON a.sales_rep_id = s.id\n",
    "JOIN region r\n",
    "ON s.region_id = r.id\n",
    "GROUP BY r.name, w.channel\n",
    "ORDER BY num_events DESC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DISTINCT`\n",
    "\n",
    "`DISTINCT` is always used in `SELECT` statements, and it provides the unique rows for all columns written in the `SELECT` statement. \n",
    "- Therefore, you only use `DISTINCT` once in any particular `SELECT` statement.\n",
    "\n",
    "You could write:\n",
    "\n",
    "```SQL\n",
    "SELECT DISTINCT column1, column2, column3\n",
    "FROM table1;\n",
    "```\n",
    "which would return **the unique rows across all three columns**.\n",
    "\n",
    "You would not write:\n",
    "```SQL\n",
    "SELECT DISTINCT column1, DISTINCT column2, DISTINCT column3\n",
    "FROM table1;\n",
    "```\n",
    "\n",
    "##### Expert tips on `DISTINCT`\n",
    "It’s worth noting that using `DISTINCT`, particularly in aggregations, can slow your queries down quite a bit.\n",
    "\n",
    "\n",
    "## `DISTINCT ` - Quiz\n",
    "\n",
    "\n",
    "1. Use `DISTINCT` to test if there are any accounts associated with more than one region.\n",
    "\n",
    "```SQL\n",
    "SELECT a.id account, r.id region\n",
    "FROM accounts a\n",
    "JOIN sales_reps s\n",
    "ON a.sales_rep_id = s.id\n",
    "JOIN region r\n",
    "ON s.region_id = r.id\n",
    "/* the number of result is 351 */\n",
    "\n",
    "SELECT DISTINCT name\n",
    "FROM accounts\n",
    "/* the number of result is 351 */\n",
    "\n",
    "/* so the result is the same, e.g. there is no account associated with more than one region */\n",
    "\n",
    "```\n",
    "\n",
    "2. Have any sales reps worked on more than one account?\n",
    "\n",
    "```SQL\n",
    "SELECT a.name account, s.name rep\n",
    "FROM accounts a\n",
    "JOIN sales_reps s\n",
    "ON a.sales_rep_id = s.id\n",
    "/* the number of results is 351*/\n",
    "\n",
    "SELECT DISTINCT name\n",
    "FROM sales_reps\n",
    "/* the number of results is 50 */\n",
    "\n",
    "/* as the first query have more results, we can know there are sales reps working on more than one account.*/ \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter aggregated result with `HAVING` \n",
    "\n",
    "`HAVING` is the “clean” way to filter a query that has been aggregated, but this is also commonly done using a **subquery**. \n",
    "\n",
    "\n",
    "##### `HAVING` v.s. `WHERE`\n",
    "\n",
    "Essentially, any time you want to perform a `WHERE` on an element of your query that was created by an aggregate, you need to use `HAVING` instead.\n",
    "\n",
    "- `WHERE` subsets the returned data based on a logical condition\n",
    "- `WHERE` appears after the `FROM`, `JOIN` and `ON` clauses, but before `GROUP BY`\n",
    "- `HAVING` appears after the `GROUP BY` clause, but before the `ORDER BY`\n",
    "- `HAVING` is like `WHERE`, but it works on logical statements involving aggregation\n",
    "\n",
    "\n",
    "## `HAVING` - Quiz\n",
    "\n",
    "1. How many of the sales reps have more than 5 accounts that they manage?\n",
    "```SQL\n",
    "SELECT sales_rep_id, COUNT(*) num_accts\n",
    "FROM accounts\n",
    "GROUP BY sales_rep_id\n",
    "HAVING COUNT(*) > 5;\n",
    "/* the number of results is 34, so the answer is 34 sales reps.\n",
    "```\n",
    "\n",
    "2. How many accounts have more than 20 orders?\n",
    "```SQL\n",
    "SELECT account_id, COUNT(*) num_orders\n",
    "FROM orders\n",
    "GROUP BY account_id\n",
    "HAVING COUNT(*) > 20;\n",
    "/* the number of result is 120, so the answer is 120 accounts.*/\n",
    "```\n",
    "\n",
    "3. Which account has the most orders?\n",
    "```SQL\n",
    "SELECT a.name, COUNT(o.*) num_orders\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "GROUP BY a.name\n",
    "ORDER BY num_orders DESC\n",
    "LIMIT 1\n",
    "/* the answer is Leucadia National, which has 71 orders.*/\n",
    "```\n",
    "\n",
    "\n",
    "4. Which accounts spent more than 30,000 usd total across all orders?\n",
    "```SQL\n",
    "SELECT a.name, SUM(total_amt_usd) total_amt\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "GROUP BY a.name\n",
    "HAVING SUM(total_amt_usd)> 30000\n",
    "ORDER BY total_amt\n",
    "```\n",
    "\n",
    "5. Which accounts spent less than 1,000 usd total across all orders?\n",
    "```SQL\n",
    "SELECT a.name, SUM(total_amt_usd) total_amt\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "GROUP BY a.name\n",
    "HAVING SUM(total_amt_usd) < 1000\n",
    "ORDER BY total_amt DESC\n",
    "```\n",
    "\n",
    "6. Which account has spent the most with us?\n",
    "```SQL\n",
    "SELECT a.name, SUM(total_amt_usd) total_amt\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "GROUP BY a.name\n",
    "ORDER BY total_amt DESC\n",
    "LIMIT 1\n",
    "```\n",
    "\n",
    "7. Which account has spent the least with us?\n",
    "```SQL\n",
    "SELECT a.name, SUM(total_amt_usd) total_amt\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "GROUP BY a.name\n",
    "ORDER BY total_amt\n",
    "LIMIT 1\n",
    "```\n",
    "\n",
    "8. Which accounts used facebook as a channel to contact customers more than 6 times?\n",
    "```SQL\n",
    "SELECT a.name, w.channel, COUNT(w.*) use_of_channel\n",
    "FROM accounts a\n",
    "JOIN web_events w\n",
    "ON w.account_id = a.id\n",
    "GROUP BY a.name, w.channel\n",
    "HAVING w.channel = 'facebook' AND count(w.*) > 6\n",
    "```\n",
    "\n",
    "9. Which account used facebook most as a channel?\n",
    "```SQL\n",
    "SELECT a.name, w.channel, COUNT(w.*) use_of_channel\n",
    "FROM accounts a\n",
    "JOIN web_events w\n",
    "ON w.account_id = a.id\n",
    "GROUP BY a.name, w.channel\n",
    "HAVING w.channel = 'facebook'\n",
    "ORDER BY use_of_channel DESC\n",
    "LIMIT 1\n",
    "```\n",
    "\n",
    "10. Which channel was most frequently used by most accounts?\n",
    "```SQL\n",
    "SELECT w.channel, COUNT(a.*) num_accounts\n",
    "FROM accounts a\n",
    "JOIN web_events w\n",
    "ON w.account_id = a.id\n",
    "GROUP BY w.channel\n",
    "ORDER BY num_accounts DESC\n",
    "LIMIT 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATE Functions\n",
    "\n",
    "\n",
    "## Date Format in SQL\n",
    "\n",
    "Date columns in SQL tend to have transaction data down to a second. They are stored in this standard format: `YYYY-MM-DD hr:min:sec+tz`, \n",
    "- for example,  `01/31/2014 08:00:00 PM +0000` shall be formated as:\n",
    "    ```SQL\n",
    "    2014-01-31 20:00:00+00\n",
    "    ```\n",
    "This format is easy for truncating, the built in SQL functions to help extract meaningful information from dates.\n",
    "\n",
    "\n",
    "## `DATE_TRUC` and `DATE_PART`\n",
    "\n",
    "- `DATE_TRUNC` allows you to truncate your date to a particular part of your date-time column. Common trunctions are `day`, `month`, and `year`. \n",
    "    - [Here](https://blog.modeanalytics.com/date-trunc-sql-timestamp-function-count-on/) is a great blog post by Mode Analytics on the power of this function.\n",
    "\n",
    "\n",
    "- `DATE_PART` can be useful for pulling a specific portion of a date, but notice pulling `month` or day of the week (`dow`) means that you are no longer keeping the years in order. Rather you are grouping for certain components regardless of which year they belonged in.\n",
    "\n",
    "\n",
    "## More Date Functions\n",
    "\n",
    "For additional functions you can use with dates in PostgreSQL, check out the documentation [here](https://www.postgresql.org/docs/9.1/static/functions-datetime.html)\n",
    "\n",
    "\n",
    "## DATE Functions - Quiz\n",
    "\n",
    "1. Find the sales in terms of total dollars for all orders in each year, ordered from greatest to least. Do you notice any trends in the yearly sales totals?\n",
    "\n",
    "```SQL\n",
    "SELECT DATE_PART('year', occurred_at) order_year, \n",
    "       sum(total_amt_usd) sum\n",
    "FROM orders\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "\n",
    "/* When we look at the yearly totals, you might notice that 2013 and 2017 have much smaller totals than all other years. If we look further at the monthly data, we see that for 2013 and 2017 there is only one month of sales for each of these years (12 for 2013 and 1 for 2017). Therefore, neither of these are evenly represented. Sales have been increasing year over year, with 2016 being the largest sales to date. At this rate, we might expect 2017 to have the largest sales.*/\n",
    "```\n",
    "\n",
    "2. Which month did Parch & Posey have the greatest sales in terms of total dollars? Are all months evenly represented by the dataset?\n",
    "\n",
    "```SQL\n",
    "SELECT DATE_PART('month', occurred_at) order_month, sum(total_amt_usd) sum\n",
    "FROM orders\n",
    "WHERE occurred_at BETWEEN '2014-01-01' AND '2017-01-01'\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "\n",
    "/*In order for this to be 'fair', we should remove the sales from 2013 and 2017. For the same reasons as discussed above.\n",
    "\n",
    "December has the greatest sales, followed by October, November and September, all of which are with sales over 2M, and the rest of the year are quite evenly distributed in the range of 1.2M - 1.9M */\n",
    "```\n",
    "\n",
    "3. Which year did Parch & Posey have the greatest sales in terms of total number of orders? Are all years evenly represented by the dataset?\n",
    "\n",
    "```SQL\n",
    "SELECT DATE_PART('year', occurred_at) order_year, \n",
    "       sum(total) sum\n",
    "FROM orders\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "```\n",
    "\n",
    "\n",
    "4. Which month did Parch & Posey have the greatest sales in terms of total number of orders? Are all months evenly represented by the dataset?\n",
    "\n",
    "```SQL\n",
    "SELECT DATE_PART('month', occurred_at) order_month, sum(total) sum\n",
    "FROM orders\n",
    "WHERE occurred_at BETWEEN '2014-01-01' AND '2017-01-01'\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "```\n",
    "\n",
    "5. In which month of which year did Walmart spend the most on gloss paper in terms of dollars?\n",
    "\n",
    "```SQL\n",
    "SELECT DATE_PART('month', o.occurred_at) order_month, sum(o.gloss_amt_usd) sum\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "WHERE a.name = 'Walmart'\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 1\n",
    "/* Walmart spend the msot on gloss paper in May 2016 */\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE Functions\n",
    "\n",
    "## `CASE`\n",
    "\n",
    "- The `CASE` statement always goes in the `SELECT` clause.\n",
    "\n",
    "\n",
    "- `CASE` must include: \n",
    "    - `WHEN`, `THEN`, and `END`. \n",
    "    - `ELSE` is an optional\n",
    "\n",
    "\n",
    "- You can make any conditional statement using any conditional operator (like `WHERE`) between `WHEN` and `THEN`. \n",
    "    - just connect multiple conditional statements with `AND` and `OR`.\n",
    "\n",
    "\n",
    "- You can include multiple `WHEN` statements, as well as an `ELSE` statement again.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## `CASE` for Aggregations\n",
    "\n",
    "### Quiz\n",
    "\n",
    "1. Write a query to display for each order, the account ID, total amount of the order, and the level of the order - ‘Large’ or ’Small’ - depending on if the order is $3000 or more, or smaller than $3000.\n",
    "```SQL\n",
    "SELECT account_id, total_amt_usd, \n",
    "\t   CASE WHEN total_amt_usd >= 3000 THEN 'Large' \n",
    "            ELSE 'Small' END AS ord_level\n",
    "FROM orders\n",
    "```\n",
    "\n",
    "2. Write a query to display the number of orders in each of three categories, based on the total number of items in each order. The three categories are: 'At Least 2000', 'Between 1000 and 2000' and 'Less than 1000'.\n",
    "```SQL\n",
    "SELECT CASE WHEN total_amt_usd >= 2000 THEN 'At Least 2000'\n",
    "\t\t\tWHEN total_amt_usd >= 1000 AND total_amt_usd < 2000 THEN 'Between 1000 and 2000'\n",
    "            ELSE 'Less than 1000' END AS ord_level,\n",
    "       COUNT(*) num_orders\n",
    "FROM orders\n",
    "GROUP BY 1\n",
    "```\n",
    "\n",
    "\n",
    "3. We would like to understand 3 different levels of customers based on the amount associated with their purchases. The top level includes anyone with a Lifetime Value (total sales of all orders) greater than 200,000 usd. The second level is between 200,000 and 100,000 usd. The lowest level is anyone under 100,000 usd. Provide a table that includes the level associated with each account. You should provide the account name, the total sales of all orders for the customer, and the level. Order with the top spending customers listed first.\n",
    "```SQL\n",
    "SELECT a.name customer, \n",
    "\t   SUM(o.total_amt_usd) total,\n",
    "       CASE WHEN SUM(o.total_amt_usd) > 200000 THEN 'top'\n",
    "       \t\tWHEN SUM(o.total_amt_usd) > 100000 THEN 'middle'\n",
    "            ELSE 'low' END AS cus_level\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "```\n",
    "\n",
    "4. We would now like to perform a similar calculation to the first, but we want to obtain the total amount spent by customers only in 2016 and 2017. Keep the same levels as in the previous question. Order with the top spending customers listed first.\n",
    "```SQL\n",
    "SELECT a.name customer, \n",
    "\t   SUM(o.total_amt_usd) total,\n",
    "       CASE WHEN SUM(o.total_amt_usd) > 200000 THEN 'top'\n",
    "       \t\tWHEN SUM(o.total_amt_usd) > 100000 THEN 'middle'\n",
    "            ELSE 'low' END AS cus_level\n",
    "FROM orders o\n",
    "JOIN accounts a\n",
    "ON o.account_id = a.id\n",
    "WHERE o.occurred_at BETWEEN '2015-12-31' AND '2018-01-01'\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "```\n",
    "\n",
    "\n",
    "5. We would like to identify top performing sales reps, which are sales reps associated with more than 200 orders. Create a table with the sales rep name, the total number of orders, and a column with top or not depending on if they have more than 200 orders. Place the top sales people first in your final table.\n",
    "```SQL\n",
    "SELECT s.name, COUNT(o.*) num_orders,\n",
    "\t   CASE WHEN COUNT(o.*) > 200 THEN 'Yes'\n",
    "            ELSE 'No' END AS is_Top\n",
    "FROM orders o\n",
    "JOIN accounts a ON o.account_id = a.id\n",
    "JOIN sales_reps s ON a.sales_rep_id = s.id\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "```\n",
    "\n",
    "6. The previous didn't account for the middle, nor the dollar amount associated with the sales. Management decides they want to see these characteristics represented as well. We would like to identify top performing sales reps, which are sales reps associated with more than 200 orders or more than 750000 in total sales. The middle group has any rep with more than 150 orders or 500000 in sales. Create a table with the sales rep name, the total number of orders, total sales across all orders, and a column with top, middle, or low depending on this criteria. Place the top sales people based on dollar amount of sales first in your final table. You might see a few upset sales people by this criteria!\n",
    "```SQL\n",
    "SELECT s.name, \n",
    "\t   COUNT(o.*) num_orders, \n",
    "       SUM(o.total_amt_usd) total_amt,\n",
    "\t   CASE WHEN COUNT(o.*) > 200 OR SUM(o.total_amt_usd) > 750000 THEN 'Top'\n",
    "            WHEN COUNT(o.*) > 150 OR SUM(o.total_amt_usd) > 500000 THEN 'Middle'\n",
    "            ELSE 'Low' END AS rep_level\n",
    "FROM orders o\n",
    "JOIN accounts a ON o.account_id = a.id\n",
    "JOIN sales_reps s ON a.sales_rep_id = s.id\n",
    "GROUP BY 1\n",
    "ORDER BY 3 DESC\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
